{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Predetermined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   day     month  year   dayname  season              stadium       city  \\\n",
      "0   10  December  2016  Saturday    2016  Quicken Loans Arena  Cleveland   \n",
      "\n",
      "  state  attendance  capacity  game_id  \\\n",
      "0  Ohio           0     19400     2596   \n",
      "\n",
      "                                             summary  \n",
      "0  LeBron James led the way for the Cavs as he we...  \n",
      "Q1: What is the name of the venue where a game was played on a day with zero attendees, despite a player scoring 44 points and achieving their 73rd 40-point game?\n",
      "A1: Quicken Loans Arena\n",
      "\n",
      "Q2: In which city did a team break another team's three-game winning streak, with a player contributing 10 assists and nearly achieving a triple-double?\n",
      "A2: Cleveland\n",
      "\n",
      "Q3: Which state hosted a game where the home team maintained their strong home record and achieved their fourth consecutive win during the winter season?\n",
      "A3: Ohio\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from openai import OpenAI\n",
    "\n",
    "df = pd.read_csv(r\"D:\\LLMTables\\LLMTablesQA\\Question Generation\\TestTables_5\\sportset_coldtemp_30_13.csv\")\n",
    "client = OpenAI()\n",
    "row = df.sample(1, random_state=random.randint(1, 1000), ignore_index=True)\n",
    "def generate_qa_pairs(row, num_pairs=1):\n",
    "    \n",
    "    # Temporal\n",
    "    prompt = f\"\"\"\n",
    "    Objective:\n",
    "    Create complex, logic-driven questions based on a dataset row that represents a real-world scenario. Each question should require multi-step reasoning, utilizing both structured and unstructured elements of the row. The questions should not directly reveal answers, instead encouraging logical deductions and practical reasoning.\n",
    "    Row Data: {row.to_dict(orient='records')[0]}\n",
    "    Guidelines for Question Generation:\n",
    "    1. Inter-Cell Logic: Questions must connect multiple data points within the row, encouraging indirect reasoning between structured and unstructured components.\n",
    "    2. Structured + Unstructured: Utilize both types of data (e.g., scores, descriptions) when formulating questions.\n",
    "    3. Avoid Direct Retrieval: Do not allow answers to be directly extracted from the row; ensure questions require reasoning.\n",
    "    4. Multi-hop Reasoning: Answers should require multiple logical operations or connections to arrive at.\n",
    "    5. Unique, Deterministic Answer: Ensure only one valid answer can be derived from the data, based on logical connections.\n",
    "    6. Simplified Language: Keep the language of questions concise and clear, avoiding unnecessary complexity.\n",
    "    7. No Word Overlap: Avoid using the same words or phrases from the row in the questions to maintain a level of difficulty.\n",
    "    Single Subtle Hint: Include one subtle clue to guide the reasoning, but ensure further deductions are needed for the correct answer.\n",
    "    9. Semantic Diversity: Aim for semantic diversity in the questions, avoiding repetition of themes or concepts.\n",
    "    \n",
    "    Example Questions + why they are good questions:\n",
    "    1. In which month did the NY Knicks team play their games, considering it was during the final quarter of the year?\n",
    "    Reason: There are just the right amount of giveaways to answer the question. You can see that the team is New York knocks and find their games at the end of the year.\n",
    "    2. Where outside USA has the boston team played?\n",
    "    Reason: \"Outside USA\" is a good marker for indirect clues which can confuse the person answering the question.\n",
    "    3. In which city did a team achieve a victory with a margin of 17 points on the last Tuesday of October? \n",
    "    Reaso8. n: There are two markers point margin and day which can help the model to filter out the information without giving too much information away.\n",
    "    4. Where was a game held that featured a standout performance of 41 points and nearly full attendance?\n",
    "\n",
    "    Take inspiration from these questions and try to make the question but not so vague that multiple answers exist in the table for that question.\n",
    "    Please note that the question should be an independent entity in terms of understanding it. This means it should not require the row on which it was created to understand the question itself. \n",
    "    Generate {num_pairs} such questions. Ensure that the answer is given in maximum 3-5 words.\n",
    "\n",
    "    Answer format:\n",
    "    Q: <Generated Question>\n",
    "    A: <Generated Answer>\n",
    "    \"\"\"\n",
    "\n",
    "    # Define your messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in generating complex questions from tabular data. Your task is to create questions that require analyzing inter-cell relationships within the provided table and can be answered directly or indirectly using the table's content. The questions should leverage both structured and unstructured components of the table data.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    # Make the API call\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # or the model you are using\n",
    "        messages=messages,\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    # Print the response\n",
    "    print(completion.choices[0].message.content)\n",
    "\n",
    "print(row)\n",
    "\n",
    "generate_qa_pairs(row, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- World Knowledge reference\n",
    "    Q: Where did a team secure a victory in a winter season game with a 9 point score difference?\n",
    "    Q: Where outside USA has the boston team played?\n",
    "\n",
    "    - Team relationships \n",
    "    Q: Which rookie was moved to the bench in favor of Louis Williams in the backcourt in an overfilled stadium?\n",
    "    Q: During which game of Kobe Bryant’s farewell tour did he score 21 points?\n",
    "    Q: Who filled in for Jonas Valanciunas due to injury and scored a season-high 15 points?\n",
    "\n",
    "- General info\n",
    "    Q: In which stadium did attendance exceed capacity during a December game?\n",
    "    Q: Which team narrowly defeated the Lakers to break a two-game losing streak?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unstructured Predetermined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   day    month  year  dayname  season           stadium     city    state  \\\n",
      "0    1  January  2019  Tuesday    2018  Scotiabank Arena  Toronto  Ontario   \n",
      "\n",
      "   attendance  capacity  game_id  \\\n",
      "0       19800     19800     5800   \n",
      "\n",
      "                                             summary  \n",
      "0  The Toronto Raptors defeated the Utah Jazz , 1...  \n",
      "Q1: Which team managed to secure a victory at a venue in Ontario after a strong third-quarter performance?\n",
      "A1: Toronto Raptors\n",
      "\n",
      "Q2: Which team overcame a halftime deficit to win a game where a player scored 45 points?\n",
      "A2: Toronto Raptors\n",
      "\n",
      "Q3: Which team played a game on the first day of a month, where their bench player contributed 14 points?\n",
      "A3: Toronto Raptors\n",
      "\n",
      "Q4: Which team played a game in a Canadian city and had a player scoring 28 points with 10 rebounds?\n",
      "A4: Toronto Raptors\n",
      "\n",
      "Q5: Which team won a game despite losing the final quarter by four points?\n",
      "A5: Toronto Raptors\n",
      "\n",
      "Q6: Which team had a player who scored 45 points in a game held on a Tuesday?\n",
      "A6: Toronto Raptors\n",
      "\n",
      "Q7: Which team played at a stadium with full attendance and had a player who filled the stat sheet with eight points, five assists, and four rebounds?\n",
      "A7: Toronto Raptors\n",
      "\n",
      "Q8: Which team was victorious in a game where their opponent's top scorer came off the bench with 30 points?\n",
      "A8: Toronto Raptors\n",
      "\n",
      "Q9: Which team played a game in January where they had a 12-point lead in the third quarter?\n",
      "A9: Toronto Raptors\n",
      "\n",
      "Q10: Which team had a player who scored 45 points in a game that took place in Toronto?\n",
      "A10: Toronto Raptors\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"D:\\LLMTables\\LLMTablesQA\\Question Generation\\TestTables_5\\sportset_coldtemp_30_13.csv\")\n",
    "client = OpenAI()\n",
    "# row = \"\"\"\n",
    "# day,month,year,dayname,season,stadium,city,state,attendance,capacity,game_id,summary\n",
    "# 7,December,2015,Monday,2015,Air Canada Centre,Toronto,Ontario,20200,19800,2100,\"The Raptors ( 13 - 9 ) escaped the Lakers ( 3 - 18 ) with a 102 - 93 victory at Air Canada Centre on Monday . Los Angeles trailed by just a point after the third quarter , but Toronto was able to pull away with five minutes remaining in the game to end a two - game losing streak . The Raptors got plenty of contributions in the fourth quarter , but the guy who carried them all game was Terrence Ross , who scored a season - high 22 points ( 8 - 12 FG , 4 - 6 3Pt , 2 - 2 FT ) over 39 minutes while also grabbing six rebounds . Kobe Bryant had a decent night shooting the ball as he continues his farewell tour , scoring 21 points on 8 - of - 16 shooting with eight boards and four assists . Larry Nance Jr. replaced Julius Randle in the starting lineup , but failed to outperform him . Randle scored 15 points ( 6 - 13 FG , 3 - 3 FT ) with 11 rebounds for his fifth double - double in six games . The other youngster moved to the bench was rookie D'Angelo Russell , who was replaced by Louis Williams alongside Jordan Clarkson in the backcourt . Russell played 21 minutes off the bench , scoring nine points on 4 - of - 12 shooting from the field . Nick Young was held out of the lineup again by coach Byron Scott . After suffering two close losses to the Nuggets and Warriors - - each at home - - the Raptors got back on track , albeit barely , against the Lakers . With center Jonas Valanciunas sidelined with a fractured hand , Bismack Biyombo has seen a bump in playing time , and finally made it count Monday . Biyombo finished with a season - high 15 points ( 4 - 8 FG , 7 - 11 FT ) with 13 rebounds and two blocks over 29 minutes . Kyle Lowry was his usual self , scoring a game - high 27 points 9 - 19 FG , 5 - 11 3Pt , 4 - 4 FT ) with seven rebounds and six assists . The Raptors will have their hands full Wednesday when the Spurs come to town ; the Lakers play the sixth game of an eight - game road trip against the T-Wolves .\"\n",
    "# \"\"\"\n",
    "row = df.sample(1, random_state=random.randint(1, 1000), ignore_index=True)\n",
    "def generate_qa_pairs(row, num_pairs=1):\n",
    "    prompt = f\"\"\"\n",
    "    Row Data: {row.to_dict(orient='records')[0]}\n",
    "\n",
    "    Objective:\n",
    "    Create simple, generalizable questions that can be answered uniquely from the given row when evaluated against the full table. The questions should:\n",
    "    - Be based on a unique property or a combination of properties from the row. Make sure that only one answer exists in the table for the question\n",
    "    - Avoid excessive specificity or anchoring to exact values, instead using general descriptions or time references (e.g., \"final Friday of November\").\n",
    "    - Be concise and intuitive, with a natural language structure.\n",
    "    - Ensure the question requires reasoning or cross-referencing across columns for a unique answer.\n",
    "    - Make sure that the answer is not too vague and is grounded to the row it is being generated by in some way.\n",
    "\n",
    "    Question Generation Guidelines:\n",
    "    1. Inter-Cell Logic: Questions must connect multiple data points within the row, encouraging indirect reasoning between structured and unstructured components.\n",
    "    2. Structured + Unstructured: Utilize both types of data (e.g., scores, descriptions) when formulating questions.\n",
    "    3. Avoid Direct Retrieval: Do not allow answers to be directly extracted from the row; ensure questions require reasoning.\n",
    "    4. Multi-hop Reasoning: Answers should require multiple logical operations or connections to arrive at.\n",
    "    5. Unique, Deterministic Answer: Ensure only one valid answer can be derived from the data, based on logical connections.\n",
    "    6. Simplified Language: Keep the language of questions concise and clear, avoiding unnecessary complexity.\n",
    "    7. No Word Overlap: Avoid using the same words or phrases from the row in the questions to maintain a level of difficulty.\n",
    "    8. Single Subtle Hint: Include one subtle clue to guide the reasoning, but ensure further deductions are needed for the correct answer.\n",
    "    9. Semantic Diversity: Aim for semantic diversity in the questions, avoiding repetition of themes or concepts.\n",
    " \n",
    "\n",
    "    Examples:\n",
    "    Q: Which team was preparing to host the Spurs following a close win over the Lakers?\n",
    "    Q: Which team was preparing to host the Rockets after rebounding from a loss to Brooklyn with a win over the Knicks?\n",
    "    Q: Which team outscored their opponent by 24 points in the first half at Madison Square Garden?\n",
    "    Q: Which team was set to face the Pelicans in New Orleans following a loss to the Cavaliers?\n",
    "    Q: Which team was heading into the All-Star break on a four-game winning streak, with a game against the Pistons up next?\n",
    "\n",
    "    **Generate {num_pairs} questions in the following format**:\n",
    "    Q: <Generated Question>\n",
    "    A: <Generated Answer>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define your messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in creating evaluation questions from tabular data. Your task is to design generalized, simple questions using unique row properties.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    # Make the API call\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",  # or the model you are using\n",
    "        messages=messages,\n",
    "        temperature=0.3 # Slightly increase temperature for creative output\n",
    "    )\n",
    "\n",
    "    # Print the response\n",
    "    print(completion.choices[0].message.content)\n",
    "\n",
    "print(row)\n",
    "\n",
    "generate_qa_pairs(row, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is: Quicken Loans Arena\n",
      "\n",
      "**Explanation:**\n",
      "To arrive at this answer, I searched through the provided table for a game where the attendance was recorded as zero. I found that on December 10, 2016, at Quicken Loans Arena, LeBron James scored 44 points, marking the 73rd 40-point game of his career. The table explicitly states that the attendance for this game was zero, which matches the criteria of the question.\n"
     ]
    }
   ],
   "source": [
    "# Prompt taken from End-to-End Qa in Chain of Table paper\n",
    "answer_prompt = f\"\"\"\n",
    "Here is the table to answer this question. Answer the question as an entity. Return an explanation on how you reached the answer.\n",
    "{string}\n",
    "Question: What is the name of the venue where a game was played on a day with zero attendees, despite a player scoring 44 points and achieving their 73rd 40-point game?\n",
    "The answer is: \n",
    "\"\"\"\n",
    "\n",
    "# Define your messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert in answering questions from tabular data.\"},\n",
    "    {\"role\": \"user\", \"content\": answer_prompt}\n",
    "]\n",
    "\n",
    "# Make the API call\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",  # or the model you are using\n",
    "    messages=messages,\n",
    "    temperature = 0.0\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"D:\\LLMTables\\LLMTablesQA\\Question Generation\\TestTables_5\\sportset_coldtemp_30_13.csv\")\n",
    "\n",
    "string = ''\n",
    "string = '/*\\n'\n",
    "col_list = df.columns.values.tolist()\n",
    "string += 'col : ' + ' | '.join(df.columns) + '\\n'\n",
    "for row_id, row in df.iterrows():\n",
    "    string += f'row {row_id} : '\n",
    "    for column_id, header in enumerate(df.columns):\n",
    "        string += str(row[header])\n",
    "        if column_id != len(df.columns) - 1:\n",
    "            string += ' | '\n",
    "    string += '\\n'\n",
    "string += '*/\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-fRla5InIDQaDKnPLyFBX0VHH on requests per day (RPD): Limit 200, Used 200, Requested 1. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 16\u001b[0m\n\u001b[0;32m     10\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     11\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an expert in answering questions from tabular data.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m     12\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: answer_prompt}\n\u001b[0;32m     13\u001b[0m ]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Make the API call\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or the model you are using\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\n\u001b[0;32m     20\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Print the response\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32mc:\\Users\\Purvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_utils\\_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Purvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\resources\\chat\\completions.py:668\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    665\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    666\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    667\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 668\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Purvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1258\u001b[0m     )\n\u001b[1;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Purvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_base_client.py:936\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    929\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    935\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Purvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_base_client.py:1025\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1024\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\Purvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_base_client.py:1074\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1074\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Purvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_base_client.py:1025\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1024\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\Purvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_base_client.py:1074\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1074\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Purvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_base_client.py:1040\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1037\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1039\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1040\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1043\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1044\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1048\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[0;32m   1049\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-fRla5InIDQaDKnPLyFBX0VHH on requests per day (RPD): Limit 200, Used 200, Requested 1. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "# Prompt taken from End-to-End Qa in Chain of Table paper\n",
    "answer_prompt = f\"\"\"\n",
    "Here is the table to answer this question. Answer the question as an entity. Return an explanation on how you reached the answer.\n",
    "{string}\n",
    "Question: In which city did a team with a home advantage struggle to maintain possession, resulting in numerous turnovers?\n",
    "The answer is: \n",
    "\"\"\"\n",
    "\n",
    "# Define your messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert in answering questions from tabular data.\"},\n",
    "    {\"role\": \"user\", \"content\": answer_prompt}\n",
    "]\n",
    "\n",
    "# Make the API call\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",  # or the model you are using\n",
    "    messages=messages,\n",
    "    temperature = 0.0\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Predetermined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Row for experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   day     month  year dayname  season          stadium      city     state  \\\n",
      "0    5  December  2014  Friday    2014  Barclays Center  Brooklyn  New York   \n",
      "\n",
      "   attendance  capacity  game_id  \\\n",
      "0       16100     17700      665   \n",
      "\n",
      "                                             summary  \n",
      "0  The Atlanta Hawks ( 12 - 6 ) defeated the Broo...  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'questions': [{'Q': 'How many games in total did the Atlanta Hawks win in the regular season before facing the Brooklyn Nets on December 5th, 2014?',\n",
       "   'A': '12'},\n",
       "  {'Q': 'Considering their previous game against the San Antonio Spurs, how many consecutive games have the Brooklyn Nets failed to achieve a .500 win ratio by December 5th, 2014?',\n",
       "   'A': '22 days'},\n",
       "  {'Q': 'What is the percentage difference in the free throw shooting efficiency between the Atlanta Hawks and the Brooklyn Nets during their game on December 5th, 2014?',\n",
       "   'A': '0%'},\n",
       "  {'Q': 'How many days before playing the Nuggets did the Atlanta Hawks extend their winning streak to five games in December 2014?',\n",
       "   'A': '2 days'},\n",
       "  {'Q': 'On what day of the week did the Brooklyn Nets fail to improve their win-loss record to .500 for the first time since November 13th, 2014?',\n",
       "   'A': 'Friday'}]}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"D:\\LLMTables\\LLMTablesQA\\Question Generation\\TestTables_5\\sportset_coldtemp_30_13.csv\")\n",
    "client = OpenAI()\n",
    "# row = \"\"\"\n",
    "# day,month,year,dayname,season,stadium,city,state,attendance,capacity,game_id,summary\n",
    "# 7,December,2015,Monday,2015,Air Canada Centre,Toronto,Ontario,20200,19800,2100,\"The Raptors ( 13 - 9 ) escaped the Lakers ( 3 - 18 ) with a 102 - 93 victory at Air Canada Centre on Monday . Los Angeles trailed by just a point after the third quarter , but Toronto was able to pull away with five minutes remaining in the game to end a two - game losing streak . The Raptors got plenty of contributions in the fourth quarter , but the guy who carried them all game was Terrence Ross , who scored a season - high 22 points ( 8 - 12 FG , 4 - 6 3Pt , 2 - 2 FT ) over 39 minutes while also grabbing six rebounds . Kobe Bryant had a decent night shooting the ball as he continues his farewell tour , scoring 21 points on 8 - of - 16 shooting with eight boards and four assists . Larry Nance Jr. replaced Julius Randle in the starting lineup , but failed to outperform him . Randle scored 15 points ( 6 - 13 FG , 3 - 3 FT ) with 11 rebounds for his fifth double - double in six games . The other youngster moved to the bench was rookie D'Angelo Russell , who was replaced by Louis Williams alongside Jordan Clarkson in the backcourt . Russell played 21 minutes off the bench , scoring nine points on 4 - of - 12 shooting from the field . Nick Young was held out of the lineup again by coach Byron Scott . After suffering two close losses to the Nuggets and Warriors - - each at home - - the Raptors got back on track , albeit barely , against the Lakers . With center Jonas Valanciunas sidelined with a fractured hand , Bismack Biyombo has seen a bump in playing time , and finally made it count Monday . Biyombo finished with a season - high 15 points ( 4 - 8 FG , 7 - 11 FT ) with 13 rebounds and two blocks over 29 minutes . Kyle Lowry was his usual self , scoring a game - high 27 points 9 - 19 FG , 5 - 11 3Pt , 4 - 4 FT ) with seven rebounds and six assists . The Raptors will have their hands full Wednesday when the Spurs come to town ; the Lakers play the sixth game of an eight - game road trip against the T-Wolves .\"\n",
    "# \"\"\"\n",
    "row = df.sample(1, random_state=random.randint(1, 1000), ignore_index=True)\n",
    "def generate_qa_pairs(row, num_pairs=1):\n",
    "    prompt = f\"\"\"\n",
    "    Row Data: {row.to_dict(orient='records')[0]}\n",
    "\n",
    "    Objective:\n",
    "        Create complex, logic-driven, temporal questions based on a dataset row that represents a real-world scenario. Each question should require multi-step reasoning, utilizing both structured and unstructured elements of the row. The questions should not directly reveal answers, instead encouraging logical deductions and practical reasoning.\n",
    "        Row Data: {row.to_dict(orient='records')[0]}\n",
    "        Guidelines for Question Generation:\n",
    "        - Self-Contained: The question should make sense on its own without needing to refer to data points from the table.\n",
    "        - Use Both Structured and Unstructured Data: Include both numbers (scores, stats) and descriptions in the question.\n",
    "        - Require Reasoning: The answer should not be directly available from the table; it should require logical thinking.\n",
    "        - Multi-Step Reasoning: Answers should involve multiple logical connections or steps to arrive at.\n",
    "        - Unique Answer: There should be only one valid answer based on the data.\n",
    "        - Clear and Simple Language: Keep the questions straightforward and easy to understand.\n",
    "        - No Word Overlap: Avoid repeating exact phrases from the row in the question.\n",
    "        - Subtle Hint: Include one subtle clue, but further reasoning should still be needed for the correct answer.\n",
    "        - Time-Based: The question should involve elements of time, comparing events or situations at different times.\n",
    "        - Focus on Season Progression: Questions should relate to different stages of the season (early, mid, late) or the timing of events.    \n",
    "    \n",
    "    Example Questions:\n",
    "        1. Which time zone did the 76ers team play in the end of november?\n",
    "        Reason: The question has minimum giveaways such as team name and a rough figure of the time period and is encouraging to look into the time zone of the game.\n",
    "        2. In which season did Minnesota Timeberwolves win a home game?\n",
    "        Reason: With the help of minimal clues such as the team name and home game it is refering to the NBA season encouraging inherent knowledge\n",
    "        3. How many days rest do the Cleveland Cavaliers have before their next game?\n",
    "        Reason: The summary mentions when the Cleveland Cavaliers play next so this encourages simple numerical reasoning over time elements\n",
    "        4. Does the game between knicks and 76ers take place in regular NBA season?\n",
    "        Reason: By looking at the row having the games between the two teams, you have to tell whether it is normal NBA season or off season\n",
    "        5. What was the Wizards' win-loss record after their last game of the 2015 season?\n",
    "        Reason: This ensure that the model goes through various wizards games to count the wins and the losses by filtering for the 2015 season.\n",
    "              \n",
    "      Please make sure that the questions do not rely on the table for understanding. Meaning they should make sense in isolation as well. Generate {num_pairs} such questions. Ensure that the answer is given in maximum 3-5 words.\n",
    "        MAKE SURE THE QUESTIONS ARE INDIRECT AND COMPLEX AND UTILIZE VARIOUS ASPECTS OF THE TABLE.\n",
    "        Please give answer in JSON format:\n",
    "        Q: <Generated Question>\n",
    "        A: <Generated Answer>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define your messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in creating evaluation questions from tabular data. Your task is to design generalized, simple questions using unique row properties.Please give valid output JSON\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    chat_completion, *_ = client.chat.completions.create(\n",
    "            model=\"gpt-4o\", \n",
    "            messages=messages,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            temperature=0.6\n",
    "    ).choices\n",
    "    content = chat_completion.message.content\n",
    "    reply = json.loads(content)\n",
    "    return reply\n",
    "\n",
    "print(row)\n",
    "\n",
    "generate_qa_pairs(row, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answering Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April 3, 2019\n"
     ]
    }
   ],
   "source": [
    "# Prompt taken from End-to-End Qa in Chain of Table paper\n",
    "answer_prompt = f\"\"\"\n",
    "Here is the table to answer this question. Answer the question as an entity. \n",
    "{string}\n",
    "Question: When did the Brooklyn Nets last play before facing the Philadelphia 76ers in the playoffs?\n",
    "The answer is: \n",
    "\"\"\"\n",
    "\n",
    "# Define your messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert in answering questions from tabular data.\"},\n",
    "    {\"role\": \"user\", \"content\": answer_prompt}\n",
    "]\n",
    "\n",
    "# Make the API call\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",  # or the model you are using\n",
    "    messages=messages,\n",
    "    temperature = 0.0\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal end-to-end generation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to D:\\LLMTables\\LLMTablesQA\\Question Generation\\Predetermined-SingleRow\\temporal_output_new.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import openai  \n",
    "\n",
    "def read_csv_files(folder_path):\n",
    "    csv_files = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            csv_files.append(file_path)\n",
    "    return csv_files\n",
    "\n",
    "def sample_row(df):\n",
    "    return df.sample(1, random_state=random.randint(1, 1000), ignore_index=True)\n",
    "\n",
    "def generate_qa_pairs(row, num_pairs=1):\n",
    "    prompt = f\"\"\"\n",
    "    Objective:\n",
    "        Create complex, logic-driven, temporal questions based on a dataset row that represents a real-world scenario. Each question should require multi-step reasoning, utilizing both structured and unstructured elements of the row. The questions should not directly reveal answers, instead encouraging logical deductions and practical reasoning.\n",
    "        Row Data: {row.to_dict(orient='records')[0]}\n",
    "        Guidelines for Question Generation:\n",
    "        1. Inter-Cell Logic: Questions must connect multiple data points within the row, encouraging indirect reasoning between structured and unstructured components.\n",
    "        2. Structured + Unstructured: Utilize both types of data (e.g., scores, descriptions) when formulating questions.\n",
    "        3. Avoid Direct Retrieval: Do not allow answers to be directly extracted from the row; ensure questions require reasoning.\n",
    "        4. Multi-hop Reasoning: Answers should require multiple logical operations or connections to arrive at.\n",
    "        5. Unique, Deterministic Answer: Ensure only one valid answer can be derived from the data, based on logical connections.\n",
    "        6. Simplified Language: Keep the language of questions concise and clear, avoiding unnecessary complexity.\n",
    "        7. No Word Overlap: Avoid using the same words or phrases from the row in the questions to maintain a level of difficulty.\n",
    "        8. Single Subtle Hint: Include one subtle clue to guide the reasoning, but ensure further deductions are needed for the correct answer.\n",
    "        10. Semantic Diversity: Aim for semantic diversity in the questions, avoiding repetition of themes or concepts.\n",
    "        11. Time Based Nature: The question should be temporal in nature, that is, it should utilize various elements of time to create logically diffcult question.\n",
    "        12. Encourage Comparative Time Reasoning: Emphasize questions that compare events or details across different time points within the row. This could involve past events, future scenarios, or comparisons within the same game. \n",
    "        13. Focus on Season Progression and Event Timing: Emphasize questions that relate to the progression within the season, such as “early,” “mid,” or “late” season positioning\n",
    "    \n",
    "    Example Questions:\n",
    "        1. Which time zone did the 76ers team play in the end of november?\n",
    "        Reason: The question has minimum giveaways such as team name and a rough figure of the time period and is encouraging to look into the time zone of the game.\n",
    "        2. In which season did Minnesota Timeberwolves win a home game?\n",
    "        Reason: With the help of minimal clues such as the team name and home game it is refering to the NBA season encouraging inherent knowledge\n",
    "        3. How many days rest do the Cleveland Cavaliers have before their next game?\n",
    "        Reason: The summary mentions when the Cleveland Cavaliers play next sothis encourages simple numerical reasoning over time elements\n",
    "        4. Does the game between knicks and 76ers take place in regular NBA season?\n",
    "        Reason: By looking at the row having the games between the two teams, you have to tell whether it is normal NBA season or off season\n",
    "        5. Which team faced a significant disadvantage due to a key player's injury while playing in February?\n",
    "        Reason: Combines a key information in summary with the month in which the game was played\n",
    "        6. Which team won against a division leader with a notable performance in December?\n",
    "        7. What was the result of a matchup where one team scored 99 points and the event took place on a January weekday in California?\n",
    "       \n",
    "        Generate {num_pairs} such questions. Ensure that the answer is given in maximum 3-5 words.\n",
    "\n",
    "        Answer format:\n",
    "        Q: <Generated Question>\n",
    "        A: <Generated Answer>\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in generating complex questions from tabular data. Your task is to create questions that require analyzing inter-cell relationships within the provided table and can be answered directly or indirectly using the table's content. The questions should leverage both structured and unstructured components of the table data.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\", \n",
    "        messages=messages,\n",
    "        temperature=0.5\n",
    "    )\n",
    "    return completion.choices[0].message.content  \n",
    "\n",
    "def process_csv_file(file_path, table_id, num_questions=5):\n",
    "    df = pd.read_csv(file_path)\n",
    "    qa_list = []\n",
    "    for i in range(num_questions):\n",
    "        row = sample_row(df) \n",
    "        qa_output = generate_qa_pairs(row, num_pairs=1) \n",
    "        question = qa_output.split(\"\\n\")[0].strip()  \n",
    "        answer = qa_output.split(\"\\n\")[1].strip()\n",
    "        question_id = f\"{table_id}_{i + 1}\"\n",
    "        qa_entry = {\n",
    "            \"question_id\": question_id,\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "            \"row\": row.to_dict(orient='records')[0], \n",
    "            \"table_id\": table_id,\n",
    "            \"table_absolute_path\": file_path,\n",
    "            \"question_type\": \"Predetermined\"\n",
    "        }\n",
    "        qa_list.append(qa_entry)\n",
    "    return qa_list\n",
    "\n",
    "def process_all_csvs(folder_path, num_questions=5):\n",
    "    output_data = {\"results\": []} \n",
    "    csv_files = read_csv_files(folder_path)\n",
    "    \n",
    "    for table_id, file_path in enumerate(csv_files):\n",
    "        qa_entries = process_csv_file(file_path, table_id, num_questions)\n",
    "        output_data[\"results\"].extend(qa_entries)\n",
    "    \n",
    "    return output_data\n",
    "\n",
    "def save_to_json(output_data, output_json_path):\n",
    "    with open(output_json_path, \"w\") as json_file:\n",
    "        json.dump(output_data, json_file, indent=4)\n",
    "    print(f\"Output saved to {output_json_path}\")\n",
    "\n",
    "def main_pipeline(folder_path, output_json_path, num_questions=5):\n",
    "    output_data = process_all_csvs(folder_path, num_questions)\n",
    "    save_to_json(output_data, output_json_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = r\"D:\\LLMTables\\LLMTablesQA\\Question Generation\\TestTables_5\"  \n",
    "    output_json_path = r\"D:\\LLMTables\\LLMTablesQA\\Question Generation\\Predetermined-SingleRow\\temporal_output_new.json\" \n",
    "    num_questions_per_csv = 5\n",
    "    main_pipeline(folder_path, output_json_path, num_questions=num_questions_per_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hard evluation pipeline (exact matching of answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total questions: 25\n",
      "incorrect answer\n",
      "Q: What was the attendance at a game where one team was in last place in their division, played in February?\n",
      "actual: 16,600\n",
      "generated: 16600\n",
      "incorrect answer\n",
      "Q: Which team managed to secure a narrow victory despite trailing in the final minutes of a game played in early December?\n",
      "actual: Memphis Grizzlies\n",
      "generated: Utah Jazz\n",
      "incorrect answer\n",
      "Q: Which team improved their record in February after a close victory at home?\n",
      "actual: Boston Celtics\n",
      "generated: Chicago Bulls\n",
      "incorrect answer\n",
      "Q: How did the Celtics perform in the third quarter of their game against Minnesota in March 2017?\n",
      "actual: Outscored Minnesota 27-17\n",
      "generated: Outscored Minnesota 27-17.\n",
      "incorrect answer\n",
      "Q: What was the attendance at the game following Detroit's loss to New York?\n",
      "actual: 18,400 fans\n",
      "generated: 13600\n",
      "incorrect answer\n",
      "Q: Which team struggled early in January but aimed for improvement later that month?\n",
      "actual: Chicago Bulls\n",
      "generated: Indiana Pacers\n",
      "incorrect answer\n",
      "Q: Which team had to adjust their strategy due to a missing player in a December game?\n",
      "actual: Boston Celtics\n",
      "generated: Philadelphia 76ers\n",
      "incorrect answer\n",
      "Q: Which team had a notable victory against a .500 opponent in mid-November?\n",
      "actual: Golden State Warriors\n",
      "generated: Brooklyn Nets\n",
      "incorrect answer\n",
      "Q: How many days did the Blazers have between their victory on the 23rd and their next game against the 76ers?\n",
      "actual: One day\n",
      "generated: Two days\n",
      "incorrect answer\n",
      "Q: How many points did the winning team score in the game before their next road matchup?\n",
      "actual: 128 points\n",
      "generated: 114 points\n",
      "incorrect answer\n",
      "Q: How many days did the Suns have to prepare for their game against the Wizards after playing on October 31?\n",
      "actual: One day\n",
      "generated: Two days.\n",
      "incorrect answer\n",
      "Q: Which team had a comeback performance in January after trailing at halftime?\n",
      "actual: Sacramento Kings\n",
      "generated: Phoenix Suns\n",
      "incorrect answer\n",
      "Q: Which team had a comeback attempt in a late February game?\n",
      "actual: Denver Nuggets\n",
      "generated: Sacramento Kings\n",
      "incorrect answer\n",
      "Q: Which team had a notable comeback attempt after trailing significantly in the middle of November?\n",
      "actual: Los Angeles Lakers\n",
      "generated: Denver Nuggets\n",
      "Total Correct Answers: 11\n",
      "Accuracy: 44.00%\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\LLMTables\\\\Question Generation\\\\incorrect_answers.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 86\u001b[0m\n\u001b[0;32m     84\u001b[0m input_json_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLLMTables\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLLMTablesQA\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mQuestion Generation\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPredetermined-SingleRow\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtemporal_output_new.json\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[0;32m     85\u001b[0m incorrect_output_json_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLLMTables\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mQuestion Generation\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mincorrect_answers.json\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[1;32m---> 86\u001b[0m \u001b[43mevaluation_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_json_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincorrect_output_json_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[110], line 81\u001b[0m, in \u001b[0;36mevaluation_pipeline\u001b[1;34m(input_json_path, incorrect_output_json_path)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Correct Answers: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect_answers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 81\u001b[0m \u001b[43msave_incorrect_answers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mincorrect_answers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincorrect_output_json_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[110], line 71\u001b[0m, in \u001b[0;36msave_incorrect_answers\u001b[1;34m(incorrect_answers, output_path)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_incorrect_answers\u001b[39m(incorrect_answers, output_path):\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[0;32m     72\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(incorrect_answers, json_file, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrectly answered questions saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\LLMTables\\\\Question Generation\\\\incorrect_answers.json'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import openai\n",
    "\n",
    "def convert_to_pipe_format(path_to_csv):\n",
    "    df = pd.read_csv(path_to_csv)\n",
    "    string = '/*\\n'\n",
    "    col_list = df.columns.values.tolist()\n",
    "    string += 'col : ' + ' | '.join(df.columns) + '\\n'\n",
    "    for row_id, row in df.iterrows():\n",
    "        string += f'row {row_id} : '\n",
    "        for column_id, header in enumerate(df.columns):\n",
    "            string += str(row[header])\n",
    "            if column_id != len(df.columns) - 1:\n",
    "                string += ' | '\n",
    "        string += '\\n'\n",
    "    string += '*/\\n'\n",
    "    string += f'columns:{col_list}\\n'\n",
    "    return string\n",
    "\n",
    "def generate_short_answer(table, question):\n",
    "    answer_prompt = f\"\"\"\n",
    "    Here is the table to answer this question. Answer the question in 3-4 words max.\n",
    "    {table}\n",
    "    Question: {question}\n",
    "    The answer is: \n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in answering questions from tabular data.\"},\n",
    "        {\"role\": \"user\", \"content\": answer_prompt}\n",
    "    ]\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\", \n",
    "        temperature=0,\n",
    "        messages=messages\n",
    "    )\n",
    "    generated_answer = completion.choices[0].message.content.strip()\n",
    "    return generated_answer\n",
    "\n",
    "def evaluate_qa_pair(qa_pair, correct_answers_list):\n",
    "    table_path = qa_pair['table_absolute_path']\n",
    "    table = convert_to_pipe_format(table_path)\n",
    "    question = qa_pair['question']\n",
    "    generated_answer = generate_short_answer(table, question)\n",
    "    correct_answer = qa_pair['answer'].replace(\"A: \", \"\").strip()\n",
    "    if generated_answer.lower() == correct_answer.lower():\n",
    "        correct_answers_list.append(qa_pair)\n",
    "        return True\n",
    "    else:\n",
    "        print(\"incorrect answer\")\n",
    "        print(question)\n",
    "        print(\"actual: \" + correct_answer)\n",
    "        print(\"generated: \" + generated_answer)\n",
    "        return False\n",
    "    \n",
    "def process_evaluation(json_data):\n",
    "    total_questions = len(json_data)\n",
    "    print(\"total questions: \" + str(total_questions))\n",
    "    correct_answers = 0\n",
    "    incorrect_answers = []\n",
    "\n",
    "    for qa_pair in json_data:\n",
    "        if evaluate_qa_pair(qa_pair, correct_answers_list=[]):\n",
    "            correct_answers += 1\n",
    "        else:\n",
    "            incorrect_answers.append(qa_pair)\n",
    "    accuracy = (correct_answers / total_questions) * 100\n",
    "    return correct_answers, accuracy, incorrect_answers\n",
    "\n",
    "def save_incorrect_answers(incorrect_answers, output_path):\n",
    "    with open(output_path, \"w\") as json_file:\n",
    "        json.dump(incorrect_answers, json_file, indent=4)\n",
    "    print(f\"Incorrectly answered questions saved to {output_path}\")\n",
    "\n",
    "def evaluation_pipeline(input_json_path, incorrect_output_json_path):\n",
    "    with open(input_json_path, \"r\") as file:\n",
    "        json_data = json.load(file)\n",
    "    correct_answers, accuracy, incorrect_answers = process_evaluation(json_data['results'])\n",
    "    print(f\"Total Correct Answers: {correct_answers}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    save_incorrect_answers(incorrect_answers, incorrect_output_json_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json_path = r\"D:\\LLMTables\\LLMTablesQA\\Question Generation\\Predetermined-SingleRow\\temporal_output_new.json\"  \n",
    "    incorrect_output_json_path = r\"D:\\LLMTables\\Question Generation\\incorrect_answers.json\"  \n",
    "    evaluation_pipeline(input_json_path, incorrect_output_json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing with GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Considering the timing of the Pelicans' win and the injuries mentioned, which player's absence is expected to impact the Magic's early season performance the most?\n",
      "\n",
      "A: Victor Oladipo\n",
      "Q: Considering the Grizzlies' recent performances, which team did they face at the end of their homestand, and what day of the week did this occur?\n",
      "\n",
      "A: Orlando Magic, Monday\n",
      "Q: Considering the Grizzlies' defensive strategy on October 28, 2017, how did their performance against the Rockets compare to their earlier season opener against the same team?\n",
      "\n",
      "A: Similar defensive dominance\n",
      "Q: How many days after Kemba Walker's wrist injury did the Hornets face the Minnesota Timberwolves at home?\n",
      "\n",
      "A: Two days later\n",
      "Q: Which team, known for strong defense but weak three-point shooting, hosted a game against a rival during the mid-season of 2015?\n",
      "\n",
      "A: Memphis Grizzlies\n",
      "Q: During which month did a team previously competing for the top conference spot suffer a downturn, yet manage a key victory against a strong opponent?\n",
      "\n",
      "A: February\n",
      "Q: During which phase of the season did the Cavaliers achieve a winning streak, highlighted by a standout performance from their star player?\n",
      "\n",
      "A: Early December\n",
      "Q: How did a key player's absence affect Toronto's performance in early December?\n",
      "\n",
      "A: Improved with Biyombo's contribution.\n",
      "Q: How did Boston's playoff chances change after their victory in early April against Toronto?  \n",
      "A: Moved to eighth\n",
      "Q: Which team had a key player missing due to injury during a February game, impacting their performance against a rival?\n",
      "\n",
      "A: Cleveland Cavaliers\n",
      "Q: Which team struggled with injuries to key players during a game on a Sunday in February 2016?\n",
      "\n",
      "A: Chicago Bulls\n",
      "Q: Considering the Pacers' performance trajectory after a key player's injury, how does their game against the Lakers reflect their mid-season form in February 2019?\n",
      "\n",
      "A: Dominant victory, strong shooting\n",
      "Q: Considering the absence of a key player, how did the home team perform in the early part of the year against a team with an even record?\n",
      "\n",
      "A: They won decisively.\n",
      "Q: Which team maintained their division lead despite a loss on a December weekday?  \n",
      "A: Toronto Raptors\n",
      "Q: Considering the absence of two important players, how did the Chicago team perform in their last February game of the 2015 season?\n",
      "\n",
      "A: They won against Lakers.\n",
      "Q: Which team secured their victory by outperforming in the final quarter during a late November Sunday game?\n",
      "\n",
      "A: Portland Trail Blazers\n",
      "Q: How many days after the Philadelphia game did Orlando play their next match in March?\n",
      "\n",
      "A: Three days later\n",
      "Q: Considering the mid-season context, which player achieved a personal milestone in a game that took place on a weekday in December?\n",
      "\n",
      "A: Dirk Nowitzki\n",
      "Q: During which month did a team play without their MVP, resulting in a significant victory in a weekday game?\n",
      "\n",
      "A: January\n",
      "Q: After which team's third straight away win in late February did a player nearly achieve a triple-double?\n",
      "\n",
      "A: Boston Celtics\n",
      "Q: During which month did the Utah Jazz secure a victory over a playoff-bound team, despite being out of postseason contention?\n",
      "\n",
      "A: April\n",
      "Q: Considering the Wizards' performance in early 2018, how did their win-loss record compare to the Nets after the overtime game?\n",
      "\n",
      "A: Wizards had more wins.\n",
      "Q: Considering the game took place in early January, which team showed a stronger bench performance?\n",
      "\n",
      "A: Denver Nuggets\n",
      "Q: Considering the timing of the game and the players' conditions, which team had the advantage of a returning key player during a late December matchup?\n",
      "\n",
      "A: Sacramento Kings\n",
      "Q: Considering the day of the week and the outcome, what was the immediate impact on Sacramento's performance streak after their late-December victory?\n",
      "\n",
      "A: Ended losing streak\n",
      "Output saved to D:\\LLMTables\\LLMTablesQA\\Question Generation\\Predetermined-SingleRow\\gpt_4o_temporal_output_new.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import openai  \n",
    "\n",
    "def read_csv_files(folder_path):\n",
    "    csv_files = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            csv_files.append(file_path)\n",
    "    return csv_files\n",
    "\n",
    "def sample_row(df):\n",
    "    return df.sample(1, random_state=random.randint(1, 1000), ignore_index=True)\n",
    "\n",
    "def generate_qa_pairs(row, num_pairs=1):\n",
    "    prompt = f\"\"\"\n",
    "    Row Data: {row.to_dict(orient='records')[0]}\n",
    "\n",
    "    Objective:\n",
    "        Create complex, logic-driven, temporal questions based on a dataset row that represents a real-world scenario. Each question should require multi-step reasoning, utilizing both structured and unstructured elements of the row. The questions should not directly reveal answers, instead encouraging logical deductions and practical reasoning.\n",
    "        Row Data: {row.to_dict(orient='records')[0]}\n",
    "        Guidelines for Question Generation:\n",
    "        - Self-Contained: The question should make sense on its own without needing to refer to data points from the table.\n",
    "        - Use Both Structured and Unstructured Data: Include both numbers (scores, stats) and descriptions in the question.\n",
    "        - Require Reasoning: The answer should not be directly available from the table; it should require logical thinking.\n",
    "        - Multi-Step Reasoning: Answers should involve multiple logical connections or steps to arrive at.\n",
    "        - Unique Answer: There should be only one valid answer based on the data.\n",
    "        - Clear and Simple Language: Keep the questions straightforward and easy to understand.\n",
    "        - No Word Overlap: Avoid repeating exact phrases from the row in the question.\n",
    "        - Subtle Hint: Include one subtle clue, but further reasoning should still be needed for the correct answer.\n",
    "        - Time-Based: The question should involve elements of time, comparing events or situations at different times.\n",
    "        - Focus on Season Progression: Questions should relate to different stages of the season (early, mid, late) or the timing of events.    \n",
    "    \n",
    "    Example Questions:\n",
    "        1. Which time zone did the 76ers team play in the end of november?\n",
    "        Reason: The question has minimum giveaways such as team name and a rough figure of the time period and is encouraging to look into the time zone of the game.\n",
    "        2. In which season did Minnesota Timeberwolves win a home game?\n",
    "        Reason: With the help of minimal clues such as the team name and home game it is refering to the NBA season encouraging inherent knowledge\n",
    "        3. How many days rest do the Cleveland Cavaliers have before their next game?\n",
    "        Reason: The summary mentions when the Cleveland Cavaliers play next so this encourages simple numerical reasoning over time elements\n",
    "        4. Does the game between knicks and 76ers take place in regular NBA season?\n",
    "        Reason: By looking at the row having the games between the two teams, you have to tell whether it is normal NBA season or off season\n",
    "        5. What was the Wizards' win-loss record after their last game of the 2015 season?\n",
    "        Reason: This ensure that the model goes through various wizards games to count the wins and the losses by filtering for the 2015 season.\n",
    "              \n",
    "      Please make sure that the questions do not rely on the table for understanding. Meaning they should make sense in isolation as well. Generate {num_pairs} such questions. Ensure that the answer is given in maximum 3-5 words.\n",
    "        MAKE SURE THE QUESTIONS ARE INDIRECT AND COMPLEX AND UTILIZE VARIOUS ASPECTS OF THE TABLE.\n",
    "        Please give answer in JSON format:\n",
    "        Q: <Generated Question>\n",
    "        A: <Generated Answer>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define your messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in creating evaluation questions from tabular data. Your task is to design generalized, simple questions using unique row properties.Please give valid output JSON\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    chat_completion, *_ = client.chat.completions.create(\n",
    "            model=\"gpt-4o\", \n",
    "            messages=messages,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            temperature=0.6\n",
    "    ).choices\n",
    "    content = chat_completion.message.content\n",
    "    reply = json.loads(content)\n",
    "    return reply\n",
    "\n",
    "def process_csv_file(file_path, table_id, num_questions=5):\n",
    "    df = pd.read_csv(file_path)\n",
    "    qa_list = []\n",
    "    for i in range(num_questions):\n",
    "        row = sample_row(df) \n",
    "        qa_output = generate_qa_pairs(row, num_pairs=1) \n",
    "        print(qa_output)\n",
    "        question = qa_output.split(\"\\n\")[0].strip()  \n",
    "        answer = qa_output.split(\"\\n\")[1].strip()\n",
    "        question_id = f\"{table_id}_{i + 1}\"\n",
    "        qa_entry = {\n",
    "            \"question_id\": question_id,\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "            \"row\": row.to_dict(orient='records')[0], \n",
    "            \"table_id\": table_id,\n",
    "            \"table_absolute_path\": file_path,\n",
    "            \"question_type\": \"Predetermined\"\n",
    "        }\n",
    "        qa_list.append(qa_entry)\n",
    "    return qa_list\n",
    "\n",
    "def process_all_csvs(folder_path, num_questions=5):\n",
    "    output_data = {\"results\": []} \n",
    "    csv_files = read_csv_files(folder_path)\n",
    "    \n",
    "    for table_id, file_path in enumerate(csv_files):\n",
    "        qa_entries = process_csv_file(file_path, table_id, num_questions)\n",
    "        output_data[\"results\"].extend(qa_entries)\n",
    "    \n",
    "    return output_data\n",
    "\n",
    "def save_to_json(output_data, output_json_path):\n",
    "    with open(output_json_path, \"w\") as json_file:\n",
    "        json.dump(output_data, json_file, indent=4)\n",
    "    print(f\"Output saved to {output_json_path}\")\n",
    "\n",
    "def main_pipeline(folder_path, output_json_path, num_questions=5):\n",
    "    output_data = process_all_csvs(folder_path, num_questions)\n",
    "    save_to_json(output_data, output_json_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = r\"D:\\LLMTables\\LLMTablesQA\\Question Generation\\TestTables_5\"  \n",
    "    output_json_path = r\"D:\\LLMTables\\LLMTablesQA\\Question Generation\\Predetermined-SingleRow\\gpt_4o_temporal_output_new.json\" \n",
    "    num_questions_per_csv = 5\n",
    "    main_pipeline(folder_path, output_json_path, num_questions=num_questions_per_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import openai\n",
    "\n",
    "def convert_to_pipe_format(path_to_csv):\n",
    "    df = pd.read_csv(path_to_csv)\n",
    "    string = '/*\\n'\n",
    "    col_list = df.columns.values.tolist()\n",
    "    string += 'col : ' + ' | '.join(df.columns) + '\\n'\n",
    "    for row_id, row in df.iterrows():\n",
    "        string += f'row {row_id} : '\n",
    "        for column_id, header in enumerate(df.columns):\n",
    "            string += str(row[header])\n",
    "            if column_id != len(df.columns) - 1:\n",
    "                string += ' | '\n",
    "        string += '\\n'\n",
    "    string += '*/\\n'\n",
    "    string += f'columns:{col_list}\\n'\n",
    "    return string\n",
    "\n",
    "def generate_short_answer(table, question):\n",
    "    answer_prompt = f\"\"\"\n",
    "    Here is the table to answer this question. Answer the question in 3-4 words max.\n",
    "    {table}\n",
    "    Question: {question}\n",
    "    The answer is: \n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in answering questions from tabular data.\"},\n",
    "        {\"role\": \"user\", \"content\": answer_prompt}\n",
    "    ]\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\", \n",
    "        temperature=0,\n",
    "        messages=messages\n",
    "    )\n",
    "    generated_answer = completion.choices[0].message.content.strip()\n",
    "    return generated_answer\n",
    "\n",
    "def evaluate_qa_pair(qa_pair, correct_answers_list):\n",
    "    table_path = qa_pair['table_absolute_path']\n",
    "    table = convert_to_pipe_format(table_path)\n",
    "    question = qa_pair['question']\n",
    "    generated_answer = generate_short_answer(table, question)\n",
    "    correct_answer = qa_pair['answer'].replace(\"A: \", \"\").strip()\n",
    "    if generated_answer.lower() == correct_answer.lower():\n",
    "        correct_answers_list.append(qa_pair)\n",
    "        return True\n",
    "    else:\n",
    "        print(\"incorrect answer\")\n",
    "        print(question)\n",
    "        print(\"actual: \" + correct_answer)\n",
    "        print(\"generated: \" + generated_answer)\n",
    "        return False\n",
    "    \n",
    "def process_evaluation(json_data):\n",
    "    total_questions = len(json_data)\n",
    "    print(\"total questions: \" + str(total_questions))\n",
    "    correct_answers = 0\n",
    "    incorrect_answers = []\n",
    "\n",
    "    for qa_pair in json_data:\n",
    "        if evaluate_qa_pair(qa_pair, correct_answers_list=[]):\n",
    "            correct_answers += 1\n",
    "        else:\n",
    "            incorrect_answers.append(qa_pair)\n",
    "    accuracy = (correct_answers / total_questions) * 100\n",
    "    return correct_answers, accuracy, incorrect_answers\n",
    "\n",
    "def save_incorrect_answers(incorrect_answers, output_path):\n",
    "    with open(output_path, \"w\") as json_file:\n",
    "        json.dump(incorrect_answers, json_file, indent=4)\n",
    "    print(f\"Incorrectly answered questions saved to {output_path}\")\n",
    "\n",
    "def evaluation_pipeline(input_json_path, incorrect_output_json_path):\n",
    "    with open(input_json_path, \"r\") as file:\n",
    "        json_data = json.load(file)\n",
    "    correct_answers, accuracy, incorrect_answers = process_evaluation(json_data['results'])\n",
    "    print(f\"Total Correct Answers: {correct_answers}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    save_incorrect_answers(incorrect_answers, incorrect_output_json_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json_path = r\"D:\\LLMTables\\LLMTablesQA\\Question Generation\\Predetermined-SingleRow\\gpt_4o_temporal_output_new.json\"  \n",
    "    incorrect_output_json_path = r\"D:\\LLMTables\\LLMTablesQA\\Question Generation\\Predetermined-SingleRow\\incorrect_answers.json\"  \n",
    "    evaluation_pipeline(input_json_path, incorrect_output_json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final temporal pipeline\n",
    "Note: change model to gpt-4o-mini as question generation on that is better. Check attached JSONs for both for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to D:\\LLMTables\\LLMTablesQA\\Question Generation\\Predetermined-SingleRow\\gpt_4o_temporal_output_new.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import openai  \n",
    "\n",
    "def read_csv_files(folder_path):\n",
    "    csv_files = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            csv_files.append(file_path)\n",
    "    return csv_files\n",
    "\n",
    "def sample_row(df):\n",
    "    return df.sample(1, random_state=random.randint(1, 1000), ignore_index=True)\n",
    "\n",
    "\n",
    "def generate_qa_pairs(row, num_pairs=1):\n",
    "    prompt = f\"\"\"\n",
    "    Row Data: {row.to_dict(orient='records')[0]}\n",
    "\n",
    "    Objective:\n",
    "        Create complex, logic-driven, simple language, temporal questions based on a dataset row that represents a real-world scenario. Each question should require multi-step reasoning, utilizing both structured and unstructured elements of the row. The questions should not directly reveal answers, instead encouraging logical deductions and practical reasoning.\n",
    "        Row Data: {row.to_dict(orient='records')[0]}\n",
    "        Guidelines for Question Generation:\n",
    "        - Make the question as natural and human sounding as possible. The language should be kept simple and human.\n",
    "        - Self-Contained: The question should make sense on its own without needing to refer to data points from the table.\n",
    "        - Use Both Structured and Unstructured Data: Include both numbers (scores, stats) and descriptions in the question.\n",
    "        - Require Reasoning: The answer should not be directly available from the table; it should require logical thinking.\n",
    "        - Multi-Step Reasoning: Answers should involve multiple logical connections or steps to arrive at.\n",
    "        - Unique Answer: There should be only one valid answer based on the data.\n",
    "        - Clear and Simple Language: Keep the questions straightforward and easy to understand.\n",
    "        - No Word Overlap: Avoid repeating exact phrases from the row in the question.\n",
    "        - Subtle Hint: Include one subtle clue, but further reasoning should still be needed for the correct answer.\n",
    "        - Time-Based: The question should involve elements of time, comparing events or situations at different times.\n",
    "        - Focus on Season Progression: Questions should relate to different stages of the season (early, mid, late) or the timing of events.    \n",
    "    \n",
    "    Example Questions:\n",
    "        1. Which time zone did the 76ers team play in the end of november?\n",
    "        Reason: The question has minimum giveaways such as team name and a rough figure of the time period and is encouraging to look into the time zone of the game.\n",
    "        2. In which season did Minnesota Timeberwolves win a home game?\n",
    "        Reason: With the help of minimal clues such as the team name and home game it is refering to the NBA season encouraging inherent knowledge\n",
    "        3. How many days rest do the Cleveland Cavaliers have before their next game?\n",
    "        Reason: The summary mentions when the Cleveland Cavaliers play next so this encourages simple numerical reasoning over time elements\n",
    "        4. Does the game between knicks and 76ers take place in regular NBA season?\n",
    "        Reason: By looking at the row having the games between the two teams, you have to tell whether it is normal NBA season or off season\n",
    "        5. What was the Wizards' win-loss record after their last game of the 2015 season?\n",
    "        Reason: This ensure that the model goes through various wizards games to count the wins and the losses by filtering for the 2015 season.\n",
    "              \n",
    "      Please make sure that the questions do not rely on the table for understanding. Meaning they should make sense in isolation as well. Generate {num_pairs} such questions. Ensure that the answer is given in maximum 3-5 words.\n",
    "        MAKE SURE THE QUESTIONS ARE INDIRECT AND COMPLEX AND UTILIZE VARIOUS ASPECTS OF THE TABLE.\n",
    "        Please give answer in JSON format:\n",
    "        Q: <Generated Question>\n",
    "        A: <Generated Answer>\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in creating evaluation questions from tabular data.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    chat_completion, *_ = client.chat.completions.create(\n",
    "        model=\"gpt-4o\", \n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        temperature=0.6\n",
    "    ).choices\n",
    "\n",
    "    content = chat_completion.message.content\n",
    "    reply = json.loads(content)\n",
    "    return reply\n",
    "\n",
    "\n",
    "def process_csv_file(file_path, table_id, num_questions=5, existing_data=None):\n",
    "    df = pd.read_csv(file_path)\n",
    "    qa_list = existing_data[\"questions\"] if existing_data else []\n",
    "\n",
    "    for i in range(num_questions):\n",
    "        row = sample_row(df) \n",
    "        qa_output = generate_qa_pairs(row, num_pairs=1) \n",
    "\n",
    "        question = qa_output[\"Q\"]\n",
    "        answer = qa_output[\"A\"]\n",
    "        question_id = f\"{table_id}_{i + 1}\"\n",
    "\n",
    "        existing_entry = next((item for item in qa_list if item[\"question_id\"] == question_id), None)\n",
    "        if existing_entry:\n",
    "            existing_entry[\"question\"] = question\n",
    "            existing_entry[\"answer\"] = answer\n",
    "            existing_entry[\"row\"] = row.to_dict(orient='records')[0]\n",
    "        else:\n",
    "            qa_entry = {\n",
    "                \"question_id\": question_id,\n",
    "                \"question\": question,\n",
    "                \"answer\": answer,\n",
    "                \"row\": row.to_dict(orient='records')[0],\n",
    "                \"table_id\": table_id,\n",
    "                \"table_absolute_path\": file_path,\n",
    "                \"question_type\": \"Predetermined\"\n",
    "            }\n",
    "            qa_list.append(qa_entry)\n",
    "\n",
    "    return {\"questions\": qa_list}\n",
    "\n",
    "def process_all_csvs(folder_path, num_questions=5, existing_data=None):\n",
    "    output_data = {\"questions\": existing_data[\"questions\"] if existing_data else []}\n",
    "    csv_files = read_csv_files(folder_path)\n",
    "    \n",
    "    for table_id, file_path in enumerate(csv_files):\n",
    "        table_data = {\n",
    "            \"questions\": [item for item in output_data[\"questions\"] if item[\"table_id\"] == table_id]\n",
    "        }\n",
    "        updated_table_data = process_csv_file(file_path, table_id, num_questions, table_data)\n",
    "        output_data[\"questions\"].extend(updated_table_data[\"questions\"])\n",
    "\n",
    "    output_data[\"questions\"] = list({v[\"question_id\"]: v for v in output_data[\"questions\"]}.values())\n",
    "    \n",
    "    return output_data\n",
    "\n",
    "\n",
    "def save_to_json(output_data, output_json_path):\n",
    "    with open(output_json_path, \"w\") as json_file:\n",
    "        json.dump(output_data, json_file, indent=4)\n",
    "    print(f\"Output saved to {output_json_path}\")\n",
    "\n",
    "def load_existing_json(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            return json.load(json_file)\n",
    "    return None\n",
    "\n",
    "def main_pipeline(folder_path, output_json_path, num_questions=5):\n",
    "    existing_data = load_existing_json(output_json_path)\n",
    "    output_data = process_all_csvs(folder_path, num_questions, existing_data)\n",
    "    save_to_json(output_data, output_json_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = r\"D:\\LLMTables\\LLMTablesQA\\Question Generation\\TestTables_5\"  \n",
    "    output_json_path = r\"D:\\LLMTables\\LLMTablesQA\\Question Generation\\Predetermined-SingleRow\\gpt_4o_temporal_output_new.json\" \n",
    "    num_questions_per_csv = 5\n",
    "    main_pipeline(folder_path, output_json_path, num_questions=num_questions_per_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total questions: 25\n",
      "incorrect answer\n",
      "Considering the Miami Heat's victory on April 5, 2017, how many days after this win do they play their next game against the Raptors?\n",
      "actual: Two days later\n",
      "generated: Two days later.\n",
      "incorrect answer\n",
      "Considering Eric Bledsoe's performance trend on Wednesdays, how might his free throw effectiveness impact his points compared to field goals over his last four games?\n",
      "actual: Relies on free throws.\n",
      "generated: Free throw reliance.\n",
      "incorrect answer\n",
      "Considering the Grizzlies' performance against the 76ers and their upcoming match, how might their confidence level compare at the start of the season versus after this game?\n",
      "actual: Higher after this game\n",
      "generated: Increased confidence level.\n",
      "incorrect answer\n",
      "If a team has won four consecutive games, and their latest victory was on a Monday in March, how many games have they won in total this season if they had 37 wins before this streak?\n",
      "actual: 41 wins\n",
      "generated: 41 games\n",
      "incorrect answer\n",
      "Considering the Bulls' performance on February 13, 2019, how many days did they have until their next game, and what does this suggest about their schedule frequency in mid-February?\n",
      "actual: Nine days, infrequent schedule\n",
      "generated: Four days until next game.\n",
      "incorrect answer\n",
      "Considering the Cavaliers' home performance, how many wins did they achieve at Quicken Loans Arena before facing the Grizzlies?\n",
      "actual: 11 wins\n",
      "generated: Four wins\n",
      "incorrect answer\n",
      "On what day did the Washington Wizards, who missed the playoffs, end their 2015 season with a win over a team that had secured a sixth seed in the Eastern Conference?\n",
      "actual: Sunday, April 10\n",
      "generated: 10 April 2016\n",
      "incorrect answer\n",
      "If the Milwaukee Bucks played a game with an attendance of 16,200 on a Monday night in February, how many days later would their next game occur if it was scheduled for Wednesday night?\n",
      "actual: 2 days later\n",
      "generated: Two days later.\n",
      "incorrect answer\n",
      "Reflecting on Kobe Bryant's final game in Chicago, how many days until the Bulls face their next opponent?\n",
      "actual: Three days\n",
      "generated: Two days.\n",
      "incorrect answer\n",
      "Considering the Bulls' injuries, how did their performance against the Lakers reflect their ability to adapt mid-season without key players?\n",
      "actual: Handled Lakers effectively\n",
      "generated: Strong offensive performance.\n",
      "incorrect answer\n",
      "Considering the Bucks' performance without their star player, how might their game strategy change by the time they face the Pacers?\n",
      "actual: Focus on rebounding.\n",
      "generated: Adjust for injuries.\n",
      "incorrect answer\n",
      "After the Pacers' victory against the Magic, how many games have the Pacers won in their last six matches, considering their recent form and injury challenges?\n",
      "actual: Four games\n",
      "generated: Four games won.\n",
      "incorrect answer\n",
      "If LeBron James had scored two fewer points in the final minutes, what would the Cavaliers' winning streak be after this game?\n",
      "actual: 10 games\n",
      "generated: Eleven games.\n",
      "incorrect answer\n",
      "Considering the Brooklyn Nets' performance against the Cleveland Cavaliers on March 27, 2015, how many days will the Cavaliers have to prepare before facing the Philadelphia 76ers?\n",
      "actual: Two days\n",
      "generated: Two days.\n",
      "incorrect answer\n",
      "Given that the Spurs played a game without Kawhi Leonard on a Monday in January 2017, what was their win-loss record after this game?\n",
      "actual: 36-9\n",
      "generated: 35 - 9\n",
      "incorrect answer\n",
      "Considering the Brooklyn Nets' home performance this season, how many home games did they win before the match on March 17, 2018?\n",
      "actual: 12 wins\n",
      "generated: 12 home wins\n",
      "incorrect answer\n",
      "Considering the performance of Spencer Dinwiddie in December 2018, how many times did he score at least 25 points in a game before his career-high against the 76ers?\n",
      "actual: Four times\n",
      "generated: Five times\n",
      "incorrect answer\n",
      "Considering the San Antonio Spurs' win on November 18, 2016, how did this victory impact their road performance for the season?\n",
      "actual: Improved to 7-0\n",
      "generated: Improved road record.\n",
      "incorrect answer\n",
      "If the Phoenix Suns played back-to-back games against the same team, what might the outcome of their next game be, considering the momentum from their previous victories?\n",
      "actual: Likely to win again\n",
      "generated: Positive momentum expected.\n",
      "incorrect answer\n",
      "Reflecting on the game held in late December 2014, how long was DeMarcus Cousins absent before making a significant comeback against the Knicks?\n",
      "actual: One day\n",
      "generated: One game absence.\n",
      "Total Correct Answers: 5\n",
      "Accuracy: 20.00%\n",
      "Incorrectly answered questions saved to D:\\LLMTables\\LLMTablesQA\\Question Generation\\Predetermined-SingleRow\\incorrect_answers.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import openai\n",
    "\n",
    "def convert_to_pipe_format(path_to_csv):\n",
    "    df = pd.read_csv(path_to_csv)\n",
    "    string = '/*\\n'\n",
    "    col_list = df.columns.values.tolist()\n",
    "    string += 'col : ' + ' | '.join(df.columns) + '\\n'\n",
    "    for row_id, row in df.iterrows():\n",
    "        string += f'row {row_id} : '\n",
    "        for column_id, header in enumerate(df.columns):\n",
    "            string += str(row[header])\n",
    "            if column_id != len(df.columns) - 1:\n",
    "                string += ' | '\n",
    "        string += '\\n'\n",
    "    string += '*/\\n'\n",
    "    string += f'columns:{col_list}\\n'\n",
    "    return string\n",
    "\n",
    "def generate_short_answer(table, question):\n",
    "    answer_prompt = f\"\"\"\n",
    "    Here is the table to answer this question. Answer the question in 3-4 words max.\n",
    "    {table}\n",
    "    Question: {question}\n",
    "    The answer is: \n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in answering questions from tabular data.\"},\n",
    "        {\"role\": \"user\", \"content\": answer_prompt}\n",
    "    ]\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\", \n",
    "        temperature=0,\n",
    "        messages=messages\n",
    "    )\n",
    "    generated_answer = completion.choices[0].message.content.strip()\n",
    "    return generated_answer\n",
    "\n",
    "def evaluate_qa_pair(qa_pair, correct_answers_list):\n",
    "    table_path = qa_pair['table_absolute_path']\n",
    "    table = convert_to_pipe_format(table_path)\n",
    "    question = qa_pair['question']\n",
    "    generated_answer = generate_short_answer(table, question)\n",
    "    correct_answer = qa_pair['answer'].replace(\"A: \", \"\").strip()\n",
    "    if generated_answer.lower() == correct_answer.lower():\n",
    "        correct_answers_list.append(qa_pair)\n",
    "        return True\n",
    "    else:\n",
    "        print(\"incorrect answer\")\n",
    "        print(question)\n",
    "        print(\"actual: \" + correct_answer)\n",
    "        print(\"generated: \" + generated_answer)\n",
    "        return False\n",
    "    \n",
    "def process_evaluation(json_data):\n",
    "    total_questions = len(json_data)\n",
    "    print(\"total questions: \" + str(total_questions))\n",
    "    correct_answers = 0\n",
    "    incorrect_answers = []\n",
    "\n",
    "    for qa_pair in json_data:\n",
    "        if evaluate_qa_pair(qa_pair, correct_answers_list=[]):\n",
    "            correct_answers += 1\n",
    "        else:\n",
    "            incorrect_answers.append(qa_pair)\n",
    "    accuracy = (correct_answers / total_questions) * 100\n",
    "    return correct_answers, accuracy, incorrect_answers\n",
    "\n",
    "def save_incorrect_answers(incorrect_answers, output_path):\n",
    "    with open(output_path, \"w\") as json_file:\n",
    "        json.dump(incorrect_answers, json_file, indent=4)\n",
    "    print(f\"Incorrectly answered questions saved to {output_path}\")\n",
    "\n",
    "def evaluation_pipeline(input_json_path, incorrect_output_json_path):\n",
    "    with open(input_json_path, \"r\") as file:\n",
    "        json_data = json.load(file)\n",
    "    correct_answers, accuracy, incorrect_answers = process_evaluation(json_data['questions'])\n",
    "    print(f\"Total Correct Answers: {correct_answers}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    save_incorrect_answers(incorrect_answers, incorrect_output_json_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json_path = r\"D:\\LLMTables\\LLMTablesQA\\Question Generation\\Predetermined-SingleRow\\gpt_4o_temporal_output_new.json\"  \n",
    "    incorrect_output_json_path = r\"D:\\LLMTables\\LLMTablesQA\\Question Generation\\Predetermined-SingleRow\\incorrect_answers.json\"  \n",
    "    evaluation_pipeline(input_json_path, incorrect_output_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-tables-qa",
   "language": "python",
   "name": "llm-tables-qa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
